{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c53102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf90f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Í≥†Ï†ï seed\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e55f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚úÖ 2. Ïû•Ïπò ÏÑ§Ï†ï\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"üìå DEVICE:\", DEVICE)\n",
    "\n",
    "# ‚úÖ 3. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ‚úÖ 4. Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎî© & Î∂ÑÎ¶¨\n",
    "dataset = datasets.ImageFolder(\"train_preprocessed\", transform=transform)\n",
    "val_ratio = 0.1\n",
    "val_size = int(len(dataset) * val_ratio)\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af437b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ïã†Î•¥Ïù¥Ï≤†\\AppData\\Local\\Temp\\ipykernel_22872\\3362017307.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ 5. Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
    "model = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=7)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# ‚úÖ 6. ÏÜêÏã§, ÏµúÏ†ÅÌôî, AMP\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e77b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Epoch 1/10:   0%|          | 0/10689 [00:00<?, ?it/s]C:\\Users\\Ïã†Î•¥Ïù¥Ï≤†\\AppData\\Local\\Temp\\ipykernel_22872\\3991835558.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "üöÄ Epoch 1/10:   2%|‚ñè         | 164/10689 [01:29<1:36:04,  1.83it/s, loss=1.57]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m     18\u001b[39m scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m scaler.update()\n\u001b[32m     22\u001b[39m train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python3.11\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python3.11\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python3.11\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ‚úÖ 7. ÌïôÏäµ Î£®ÌîÑ\n",
    "best_f1 = 0\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"üöÄ Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix(loss=train_loss / (loop.n + 1))\n",
    "\n",
    "    # ‚úÖ 8. Í≤ÄÏ¶ù\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(labels.numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "    print(f\"üìä Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'best_mobilenetv3.pt')\n",
    "        print(f\"üíæ Best model saved (F1: {best_f1:.4f})\")\n",
    "\n",
    "print(\"‚úÖ ÌïôÏäµ ÏôÑÎ£å\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
